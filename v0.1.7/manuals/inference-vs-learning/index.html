<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Inference vs Learning · RxInferServer</title><meta name="title" content="Inference vs Learning · RxInferServer"/><meta property="og:title" content="Inference vs Learning · RxInferServer"/><meta property="twitter:title" content="Inference vs Learning · RxInferServer"/><meta name="description" content="A RESTful HTTP server implementation for RxInfer.jl, a reactive message passing inference engine for probabilistic models."/><meta property="og:description" content="A RESTful HTTP server implementation for RxInfer.jl, a reactive message passing inference engine for probabilistic models."/><meta property="twitter:description" content="A RESTful HTTP server implementation for RxInfer.jl, a reactive message passing inference engine for probabilistic models."/><meta property="og:url" content="https://server.rxinfer.com/manuals/inference-vs-learning/"/><meta property="twitter:url" content="https://server.rxinfer.com/manuals/inference-vs-learning/"/><link rel="canonical" href="https://server.rxinfer.com/manuals/inference-vs-learning/"/><script async src="https://www.googletagmanager.com/gtag/js?id=G-TCF3D8BVYF"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-TCF3D8BVYF', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">RxInferServer</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../getting-started/">Getting started</a></li><li><span class="tocitem">API design</span><ul><li><a class="tocitem" href="../../api/authentication/">Authentication</a></li><li><a class="tocitem" href="../../api/model-management/">Model management</a></li><li><a class="tocitem" href="../../api/learning/">Learning parameters of a model</a></li><li><a class="tocitem" href="../../api/status-codes/">Status codes and error handling</a></li><li><a class="tocitem" href="../../api/server-info/">Server details and version</a></li><li><a class="tocitem" href="../../api/request-preferences/">Request preferences</a></li></ul></li><li><a class="tocitem" href="../../configuration/">Configuration</a></li><li><span class="tocitem">Manuals</span><ul><li><a class="tocitem" href="../how-to-add-a-model/">How to add a model</a></li><li class="is-active"><a class="tocitem" href>Inference vs Learning</a><ul class="internal"><li><a class="tocitem" href="#The-Core-Concept"><span>The Core Concept</span></a></li><li><a class="tocitem" href="#Prerequisites"><span>Prerequisites</span></a></li><li><a class="tocitem" href="#Setting-Up-the-Example"><span>Setting Up the Example</span></a></li><li><a class="tocitem" href="#Initial-Learning-Phase"><span>Initial Learning Phase</span></a></li><li><a class="tocitem" href="#The-Inference-vs-Learning-Distinction"><span>The Inference vs Learning Distinction</span></a></li><li><a class="tocitem" href="#Key-Insights"><span>Key Insights</span></a></li><li><a class="tocitem" href="#Practical-Applications"><span>Practical Applications</span></a></li><li><a class="tocitem" href="#Cleaning-Up"><span>Cleaning Up</span></a></li><li><a class="tocitem" href="#Summary"><span>Summary</span></a></li></ul></li><li><a class="tocitem" href="../continual-learning/">Continual learning</a></li></ul></li><li><span class="tocitem">Server components</span><ul><li><a class="tocitem" href="../../components/models/">Models</a></li><li><a class="tocitem" href="../../components/database/">Database</a></li><li><a class="tocitem" href="../../components/logging/">Logging</a></li><li><a class="tocitem" href="../../components/serialization/">Serialization</a></li></ul></li><li><a class="tocitem" href="../../developers-guide/">Developers guide</a></li><li><span class="tocitem">OpenAPI documentation</span><ul><li><a class="tocitem" href="../../openapi/">Overview</a></li><li><input class="collapse-toggle" id="menuitem-8-2" type="checkbox"/><label class="tocitem" for="menuitem-8-2"><span class="docs-label">Server</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../openapi/README/">Overview</a></li><li><input class="collapse-toggle" id="menuitem-8-2-2" type="checkbox"/><label class="tocitem" for="menuitem-8-2-2"><span class="docs-label">Apis</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../openapi/Apis/AuthenticationApi/">AuthenticationApi</a></li><li><a class="tocitem" href="../../openapi/Apis/ModelsApi/">ModelsApi</a></li><li><a class="tocitem" href="../../openapi/Apis/ServerApi/">ServerApi</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-8-2-3" type="checkbox"/><label class="tocitem" for="menuitem-8-2-3"><span class="docs-label">Models</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../openapi/Models/AttachEventsToEpisodeRequest/">AttachEventsToEpisodeRequest</a></li><li><a class="tocitem" href="../../openapi/Models/AttachEventsToEpisodeRequest_events_inner/">AttachEventsToEpisodeRequest<em>events</em>inner</a></li><li><a class="tocitem" href="../../openapi/Models/AttachMetadataToEventRequest/">AttachMetadataToEventRequest</a></li><li><a class="tocitem" href="../../openapi/Models/AvailableModel/">AvailableModel</a></li><li><a class="tocitem" href="../../openapi/Models/AvailableModel_details/">AvailableModel_details</a></li><li><a class="tocitem" href="../../openapi/Models/CreateEpisodeRequest/">CreateEpisodeRequest</a></li><li><a class="tocitem" href="../../openapi/Models/CreateModelInstanceRequest/">CreateModelInstanceRequest</a></li><li><a class="tocitem" href="../../openapi/Models/CreateModelInstanceResponse/">CreateModelInstanceResponse</a></li><li><a class="tocitem" href="../../openapi/Models/DeleteModelInstanceRequest/">DeleteModelInstanceRequest</a></li><li><a class="tocitem" href="../../openapi/Models/EpisodeInfo/">EpisodeInfo</a></li><li><a class="tocitem" href="../../openapi/Models/ErrorResponse/">ErrorResponse</a></li><li><a class="tocitem" href="../../openapi/Models/InferRequest/">InferRequest</a></li><li><a class="tocitem" href="../../openapi/Models/InferResponse/">InferResponse</a></li><li><a class="tocitem" href="../../openapi/Models/LearnRequest/">LearnRequest</a></li><li><a class="tocitem" href="../../openapi/Models/LearnResponse/">LearnResponse</a></li><li><a class="tocitem" href="../../openapi/Models/ModelInstance/">ModelInstance</a></li><li><a class="tocitem" href="../../openapi/Models/ModelInstanceParameters/">ModelInstanceParameters</a></li><li><a class="tocitem" href="../../openapi/Models/ModelInstanceState/">ModelInstanceState</a></li><li><a class="tocitem" href="../../openapi/Models/NotFoundResponse/">NotFoundResponse</a></li><li><a class="tocitem" href="../../openapi/Models/PingResponse/">PingResponse</a></li><li><a class="tocitem" href="../../openapi/Models/ServerInfo/">ServerInfo</a></li><li><a class="tocitem" href="../../openapi/Models/SuccessResponse/">SuccessResponse</a></li><li><a class="tocitem" href="../../openapi/Models/TokenGenerateResponse/">TokenGenerateResponse</a></li><li><a class="tocitem" href="../../openapi/Models/TokenRolesResponse/">TokenRolesResponse</a></li><li><a class="tocitem" href="../../openapi/Models/UnauthorizedResponse/">UnauthorizedResponse</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-8-3" type="checkbox"/><label class="tocitem" for="menuitem-8-3"><span class="docs-label">Client</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../openapi/README/">Overview</a></li><li><input class="collapse-toggle" id="menuitem-8-3-2" type="checkbox"/><label class="tocitem" for="menuitem-8-3-2"><span class="docs-label">Apis</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../openapi/Apis/AuthenticationApi/">AuthenticationApi</a></li><li><a class="tocitem" href="../../openapi/Apis/ModelsApi/">ModelsApi</a></li><li><a class="tocitem" href="../../openapi/Apis/ServerApi/">ServerApi</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-8-3-3" type="checkbox"/><label class="tocitem" for="menuitem-8-3-3"><span class="docs-label">Models</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../openapi/Models/AttachEventsToEpisodeRequest/">AttachEventsToEpisodeRequest</a></li><li><a class="tocitem" href="../../openapi/Models/AttachEventsToEpisodeRequest_events_inner/">AttachEventsToEpisodeRequest<em>events</em>inner</a></li><li><a class="tocitem" href="../../openapi/Models/AttachMetadataToEventRequest/">AttachMetadataToEventRequest</a></li><li><a class="tocitem" href="../../openapi/Models/AvailableModel/">AvailableModel</a></li><li><a class="tocitem" href="../../openapi/Models/AvailableModel_details/">AvailableModel_details</a></li><li><a class="tocitem" href="../../openapi/Models/CreateEpisodeRequest/">CreateEpisodeRequest</a></li><li><a class="tocitem" href="../../openapi/Models/CreateModelInstanceRequest/">CreateModelInstanceRequest</a></li><li><a class="tocitem" href="../../openapi/Models/CreateModelInstanceResponse/">CreateModelInstanceResponse</a></li><li><a class="tocitem" href="../../openapi/Models/DeleteModelInstanceRequest/">DeleteModelInstanceRequest</a></li><li><a class="tocitem" href="../../openapi/Models/EpisodeInfo/">EpisodeInfo</a></li><li><a class="tocitem" href="../../openapi/Models/ErrorResponse/">ErrorResponse</a></li><li><a class="tocitem" href="../../openapi/Models/InferRequest/">InferRequest</a></li><li><a class="tocitem" href="../../openapi/Models/InferResponse/">InferResponse</a></li><li><a class="tocitem" href="../../openapi/Models/LearnRequest/">LearnRequest</a></li><li><a class="tocitem" href="../../openapi/Models/LearnResponse/">LearnResponse</a></li><li><a class="tocitem" href="../../openapi/Models/ModelInstance/">ModelInstance</a></li><li><a class="tocitem" href="../../openapi/Models/ModelInstanceParameters/">ModelInstanceParameters</a></li><li><a class="tocitem" href="../../openapi/Models/ModelInstanceState/">ModelInstanceState</a></li><li><a class="tocitem" href="../../openapi/Models/NotFoundResponse/">NotFoundResponse</a></li><li><a class="tocitem" href="../../openapi/Models/PingResponse/">PingResponse</a></li><li><a class="tocitem" href="../../openapi/Models/ServerInfo/">ServerInfo</a></li><li><a class="tocitem" href="../../openapi/Models/SuccessResponse/">SuccessResponse</a></li><li><a class="tocitem" href="../../openapi/Models/TokenGenerateResponse/">TokenGenerateResponse</a></li><li><a class="tocitem" href="../../openapi/Models/TokenRolesResponse/">TokenRolesResponse</a></li><li><a class="tocitem" href="../../openapi/Models/UnauthorizedResponse/">UnauthorizedResponse</a></li></ul></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manuals</a></li><li class="is-active"><a href>Inference vs Learning</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Inference vs Learning</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/lazydynamics/RxInferServer" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/lazydynamics/RxInferServer/blob/main/docs/src/manuals/inference-vs-learning.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Inference-vs-Learning:-Understanding-the-Difference"><a class="docs-heading-anchor" href="#Inference-vs-Learning:-Understanding-the-Difference">Inference vs Learning: Understanding the Difference</a><a id="Inference-vs-Learning:-Understanding-the-Difference-1"></a><a class="docs-heading-anchor-permalink" href="#Inference-vs-Learning:-Understanding-the-Difference" title="Permalink"></a></h1><p>This guide explains the fundamental difference between inference and learning calls in RxInferServer, using the Beta-Bernoulli model as a practical example. Understanding this distinction is crucial for building effective continual learning systems.</p><h2 id="The-Core-Concept"><a class="docs-heading-anchor" href="#The-Core-Concept">The Core Concept</a><a id="The-Core-Concept-1"></a><a class="docs-heading-anchor-permalink" href="#The-Core-Concept" title="Permalink"></a></h2><p>In RxInferServer, <strong>inference</strong> and <strong>learning</strong> serve different purposes:</p><ul><li><strong>Inference</strong>: Provides immediate predictions using current model parameters, but doesn&#39;t update them</li><li><strong>Learning</strong>: Processes accumulated data and permanently updates the model&#39;s parameters</li></ul><h2 id="Prerequisites"><a class="docs-heading-anchor" href="#Prerequisites">Prerequisites</a><a id="Prerequisites-1"></a><a class="docs-heading-anchor-permalink" href="#Prerequisites" title="Permalink"></a></h2><p>Before using the Learning API, you need a valid authentication token. If you haven&#39;t obtained one yet, please refer to the <a href="../../api/authentication/#authentication-api">Authentication</a> guide.</p><pre><code class="language-julia hljs">import RxInferClientOpenAPI.OpenAPI.Clients: Client
import RxInferClientOpenAPI: ModelsApi

client = Client(basepath(ModelsApi); headers = Dict(
    &quot;Authorization&quot; =&gt; &quot;Bearer $token&quot;
))

api = ModelsApi(client)</code></pre><h2 id="Setting-Up-the-Example"><a class="docs-heading-anchor" href="#Setting-Up-the-Example">Setting Up the Example</a><a id="Setting-Up-the-Example-1"></a><a class="docs-heading-anchor-permalink" href="#Setting-Up-the-Example" title="Permalink"></a></h2><p>Let&#39;s create a Beta-Bernoulli model to track the success rate of a feature. We&#39;ll start with a uniform prior (α=1, β=1) and observe how inference and learning interact.</p><pre><code class="language-julia hljs">import RxInferClientOpenAPI: create_model_instance, CreateModelInstanceRequest

request = CreateModelInstanceRequest(
    model_name = &quot;BetaBernoulli-v1&quot;,
    description = &quot;Understanding inference vs learning&quot;,
    arguments = Dict(&quot;prior_a&quot; =&gt; 1, &quot;prior_b&quot; =&gt; 1)
)

response, _ = create_model_instance(api, request)
instance_id = response.instance_id</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">&quot;a7de07b2-d381-46ea-80d9-648e54727eb1&quot;</code></pre><h2 id="Initial-Learning-Phase"><a class="docs-heading-anchor" href="#Initial-Learning-Phase">Initial Learning Phase</a><a id="Initial-Learning-Phase-1"></a><a class="docs-heading-anchor-permalink" href="#Initial-Learning-Phase" title="Permalink"></a></h2><p>First, let&#39;s load some data and learn from it:</p><pre><code class="language-julia hljs">import RxInferClientOpenAPI: attach_events_to_episode, AttachEventsToEpisodeRequest, LearnRequest, run_learning

# Load initial data: 8 successes out of 10 trials
initial_data = [1, 1, 0, 1, 1, 1, 0, 1, 1, 1]
events = [Dict(&quot;data&quot; =&gt; Dict(&quot;observation&quot; =&gt; obs)) for obs in initial_data]

# Visualize the initial data distribution
p1 = bar([0, 1], [count(==(0), initial_data), count(==(1), initial_data)],
         label=&quot;Initial Data (8 successes, 2 failures)&quot;,
         color=:lightblue, alpha=0.7)
plot!(p1, title=&quot;Initial Data Distribution&quot;, xlabel=&quot;Observation&quot;, ylabel=&quot;Count&quot;,
      xticks=([0, 1], [&quot;Failure (0)&quot;, &quot;Success (1)&quot;]))
p1</code></pre><img src="9ba5ba95.svg" alt="Example block output"/><pre><code class="language-julia hljs">attach_request = AttachEventsToEpisodeRequest(events = events)
attach_response, _ = attach_events_to_episode(api, instance_id, &quot;default&quot;, attach_request)
attach_response</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">{
  &quot;message&quot;: &quot;Events attached to the episode successfully&quot;
}
</code></pre><pre><code class="language-julia hljs"># Learn from the initial data
learn_request = LearnRequest(episodes = [&quot;default&quot;])
learn_response, _ = run_learning(api, instance_id, learn_request)
learn_response</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">{
  &quot;learned_parameters&quot;: {
    &quot;posterior_a&quot;: 9,
    &quot;posterior_b&quot;: 3
  }
}
</code></pre><p>After learning, our model has updated parameters: α=9, β=3 (1+8 successes, 1+2 failures).</p><pre><code class="language-julia hljs"># Visualize the posterior distribution after initial learning
posterior_after_learning = Beta(9, 3)
p2 = plot(0:0.01:1, pdf.(posterior_after_learning, 0:0.01:1),
          label=&quot;Posterior after Learning (α=9, β=3)&quot;,
          color=:blue, lw=2, title=&quot;Posterior Distribution After Initial Learning&quot;)
vline!(p2, [mean(posterior_after_learning)],
       label=&quot;Mean: $(round(mean(posterior_after_learning), digits=3))&quot;,
       linestyle=:dash, color=:red)
plot!(p2, xlabel=&quot;Success Probability&quot;, ylabel=&quot;Density&quot;)
p2</code></pre><img src="066b92c3.svg" alt="Example block output"/><h2 id="The-Inference-vs-Learning-Distinction"><a class="docs-heading-anchor" href="#The-Inference-vs-Learning-Distinction">The Inference vs Learning Distinction</a><a id="The-Inference-vs-Learning-Distinction-1"></a><a class="docs-heading-anchor-permalink" href="#The-Inference-vs-Learning-Distinction" title="Permalink"></a></h2><p>Now let&#39;s demonstrate the key difference. We&#39;ll make multiple inference calls and observe that the model parameters don&#39;t change until we explicitly call learning.</p><h3 id="Making-Inference-Calls"><a class="docs-heading-anchor" href="#Making-Inference-Calls">Making Inference Calls</a><a id="Making-Inference-Calls-1"></a><a class="docs-heading-anchor-permalink" href="#Making-Inference-Calls" title="Permalink"></a></h3><pre><code class="language-julia hljs">import RxInferClientOpenAPI: InferRequest, run_inference

# First inference call
inference_request = InferRequest(data = Dict(&quot;observation&quot; =&gt; 1))
inference_response, _ = run_inference(api, instance_id, inference_request)
inference_response</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">{
  &quot;event_id&quot;: 11,
  &quot;results&quot;: {
    &quot;mean_p&quot;: 0.7692307692307693,
    &quot;number_of_infer_calls&quot;: 1
  },
  &quot;errors&quot;: []
}
</code></pre><pre><code class="language-julia hljs"># Second inference call with the same observation
inference_response, _ = run_inference(api, instance_id, inference_request)
inference_response</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">{
  &quot;event_id&quot;: 12,
  &quot;results&quot;: {
    &quot;mean_p&quot;: 0.7692307692307693,
    &quot;number_of_infer_calls&quot;: 2
  },
  &quot;errors&quot;: []
}
</code></pre><p>Notice that both inference calls return the same result: mean_p ≈ 0.565. This is because <strong>inference doesn&#39;t update the model parameters</strong> - it uses the current parameters (α=9, β=3) to make predictions.</p><pre><code class="language-julia hljs"># Visualize the inference results - both calls should give the same result
inference_means = [0.565, 0.565]  # Both inference calls return the same mean
p3 = bar([&quot;Inference 1&quot;, &quot;Inference 2&quot;], inference_means,
         label=&quot;Inference Results&quot;, color=:orange, alpha=0.7)
plot!(p3, title=&quot;Inference Results (Same Parameters)&quot;,
      ylabel=&quot;Predicted Success Probability&quot;, ylims=(0.5, 0.6))
p3</code></pre><img src="b4efed26.svg" alt="Example block output"/><h3 id="Unprocessed-Events"><a class="docs-heading-anchor" href="#Unprocessed-Events">Unprocessed Events</a><a id="Unprocessed-Events-1"></a><a class="docs-heading-anchor-permalink" href="#Unprocessed-Events" title="Permalink"></a></h3><p>We can verify that certain events are not processed yet:</p><pre><code class="language-julia hljs">import RxInferClientOpenAPI: get_episode_info

episode_info, _ = get_episode_info(api, instance_id, &quot;default&quot;)
episode_info.events</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">12-element Vector{Dict{String, Any}}:
 Dict(&quot;event_id&quot; =&gt; 1, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 2, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 3, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 0), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 4, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 5, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 6, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 7, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 0), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 8, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 9, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 10, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 11, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.630&quot;, &quot;processed&quot; =&gt; false)
 Dict(&quot;event_id&quot; =&gt; 12, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.642&quot;, &quot;processed&quot; =&gt; false)</code></pre><pre><code class="language-julia hljs">unprocessed_events = filter(episode_info.events) do event
    return !get(event, &quot;processed&quot;, false)
end
unprocessed_events</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Dict{String, Any}}:
 Dict(&quot;event_id&quot; =&gt; 11, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.630&quot;, &quot;processed&quot; =&gt; false)
 Dict(&quot;event_id&quot; =&gt; 12, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.642&quot;, &quot;processed&quot; =&gt; false)</code></pre><h3 id="The-Learning-Step"><a class="docs-heading-anchor" href="#The-Learning-Step">The Learning Step</a><a id="The-Learning-Step-1"></a><a class="docs-heading-anchor-permalink" href="#The-Learning-Step" title="Permalink"></a></h3><p>If we call learning now, it will use only the unprocessed events and the previously learned parameters to learn the new parameters. Now let&#39;s call learning to process to demonstrate this:</p><pre><code class="language-julia hljs"># Learn from the accumulated inference events
learn_request = LearnRequest(episodes = [&quot;default&quot;])
learn_response, _ = run_learning(api, instance_id, learn_request)
learn_response</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">{
  &quot;learned_parameters&quot;: {
    &quot;posterior_a&quot;: 11,
    &quot;posterior_b&quot;: 3
  }
}
</code></pre><p>After learning, the parameters have updated to α=11, β=3 (9+2 successes, 3+0 failures). The two inference calls with observation=1 have been processed now.</p><pre><code class="language-julia hljs"># Visualize the updated posterior distribution after learning
posterior_after_learning_2 = Beta(11, 3)
p4 = plot(0:0.01:1, pdf.(posterior_after_learning_2, 0:0.01:1),
          label=&quot;Posterior after Learning (α=11, β=3)&quot;,
          color=:green, lw=2, title=&quot;Posterior Distribution After Processing Inference Events&quot;)
vline!(p4, [mean(posterior_after_learning_2)],
       label=&quot;Mean: $(round(mean(posterior_after_learning_2), digits=3))&quot;,
       linestyle=:dash, color=:red)
plot!(p4, xlabel=&quot;Success Probability&quot;, ylabel=&quot;Density&quot;)
p4</code></pre><img src="d25c0309.svg" alt="Example block output"/><pre><code class="language-julia hljs">episode_info, _ = get_episode_info(api, instance_id, &quot;default&quot;)
episode_info.events</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">12-element Vector{Dict{String, Any}}:
 Dict(&quot;event_id&quot; =&gt; 1, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 2, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 3, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 0), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 4, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 5, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 6, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 7, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 0), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 8, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 9, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 10, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;metadata&quot; =&gt; Dict{String, Any}(), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.550&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 11, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.630&quot;, &quot;processed&quot; =&gt; true)
 Dict(&quot;event_id&quot; =&gt; 12, &quot;data&quot; =&gt; Dict{String, Any}(&quot;observation&quot; =&gt; 1), &quot;timestamp&quot; =&gt; &quot;2025-10-01T11:34:48.642&quot;, &quot;processed&quot; =&gt; true)</code></pre><pre><code class="language-julia hljs">unprocessed_events = filter(episode_info.events) do event
    return !get(event, &quot;processed&quot;, false)
end
unprocessed_events</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Dict{String, Any}[]</code></pre><h3 id="Inference-After-Learning"><a class="docs-heading-anchor" href="#Inference-After-Learning">Inference After Learning</a><a id="Inference-After-Learning-1"></a><a class="docs-heading-anchor-permalink" href="#Inference-After-Learning" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Inference after learning - now uses updated parameters
inference_response, _ = run_inference(api, instance_id, inference_request)
inference_response</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">{
  &quot;event_id&quot;: 13,
  &quot;results&quot;: {
    &quot;mean_p&quot;: 0.8,
    &quot;number_of_infer_calls&quot;: 3
  },
  &quot;errors&quot;: []
}
</code></pre><p>Now the inference uses the updated parameters (α=11, β=3), resulting in mean_p ≈ 0.571.</p><pre><code class="language-julia hljs"># Visualize the final inference result with updated parameters
final_inference_mean = 0.571
p5 = bar([&quot;Final Inference&quot;], [final_inference_mean],
         label=&quot;Final Inference Result&quot;, color=:purple, alpha=0.7)
plot!(p5, title=&quot;Final Inference (Updated Parameters)&quot;,
      ylabel=&quot;Predicted Success Probability&quot;, ylims=(0.5, 0.6))
p5</code></pre><img src="d6b10165.svg" alt="Example block output"/><pre><code class="language-julia hljs"># Compare all posterior distributions
p6 = plot(title=&quot;Evolution of Posterior Distributions&quot;, xlabel=&quot;Success Probability&quot;, ylabel=&quot;Density&quot;, legend=:topright)

# Initial prior
prior = Beta(1, 1)
plot!(p6, 0:0.01:1, pdf.(prior, 0:0.01:1), label=&quot;Initial Prior (α=1, β=1)&quot;, color=:gray, lw=2)

# After initial learning
posterior_1 = Beta(9, 3)
plot!(p6, 0:0.01:1, pdf.(posterior_1, 0:0.01:1), label=&quot;After Initial Learning (α=9, β=3)&quot;, color=:blue, lw=2)

# After processing inference events
posterior_2 = Beta(11, 3)
plot!(p6, 0:0.01:1, pdf.(posterior_2, 0:0.01:1), label=&quot;After Processing Inference (α=11, β=3)&quot;, color=:green, lw=2)

# Add vertical lines for means
vline!(p6, [mean(prior)], label=&quot;Prior Mean: $(round(mean(prior), digits=3))&quot;, linestyle=:dash, color=:gray)
vline!(p6, [mean(posterior_1)], label=&quot;Learning Mean: $(round(mean(posterior_1), digits=3))&quot;, linestyle=:dash, color=:blue)
vline!(p6, [mean(posterior_2)], label=&quot;Final Mean: $(round(mean(posterior_2), digits=3))&quot;, linestyle=:dash, color=:green)

p6</code></pre><img src="23104dc9.svg" alt="Example block output"/><h2 id="Key-Insights"><a class="docs-heading-anchor" href="#Key-Insights">Key Insights</a><a id="Key-Insights-1"></a><a class="docs-heading-anchor-permalink" href="#Key-Insights" title="Permalink"></a></h2><h3 id="1.-**Inference-is-Non-Persistent**"><a class="docs-heading-anchor" href="#1.-**Inference-is-Non-Persistent**">1. <strong>Inference is Non-Persistent</strong></a><a id="1.-**Inference-is-Non-Persistent**-1"></a><a class="docs-heading-anchor-permalink" href="#1.-**Inference-is-Non-Persistent**" title="Permalink"></a></h3><ul><li>Inference calls don&#39;t update the model&#39;s learned parameters</li><li>Each inference call uses the current parameters as the prior</li></ul><h3 id="2.-**Learning-is-Persistent**"><a class="docs-heading-anchor" href="#2.-**Learning-is-Persistent**">2. <strong>Learning is Persistent</strong></a><a id="2.-**Learning-is-Persistent**-1"></a><a class="docs-heading-anchor-permalink" href="#2.-**Learning-is-Persistent**" title="Permalink"></a></h3><ul><li>Learning processes all unprocessed events and updates parameters</li><li>Changes are permanent and affect future inference calls</li><li>Enables efficient batch processing of accumulated data</li></ul><h3 id="3.-**The-Workflow**"><a class="docs-heading-anchor" href="#3.-**The-Workflow**">3. <strong>The Workflow</strong></a><a id="3.-**The-Workflow**-1"></a><a class="docs-heading-anchor-permalink" href="#3.-**The-Workflow**" title="Permalink"></a></h3><pre><code class="nohighlight hljs">Data → Inference (immediate feedback) → Learning (persistent update) → Inference (updated feedback)</code></pre><h2 id="Practical-Applications"><a class="docs-heading-anchor" href="#Practical-Applications">Practical Applications</a><a id="Practical-Applications-1"></a><a class="docs-heading-anchor-permalink" href="#Practical-Applications" title="Permalink"></a></h2><p>This design pattern is particularly useful for:</p><ul><li><strong>Real-time Systems</strong>: Get immediate predictions while batching updates</li><li><strong>Streaming Data</strong>: Process data as it arrives, update models periodically</li><li><strong>Resource Management</strong>: Control when computationally expensive learning occurs</li><li><strong>Continual Learning</strong>: Efficiently update models with new information</li></ul><h2 id="Cleaning-Up"><a class="docs-heading-anchor" href="#Cleaning-Up">Cleaning Up</a><a id="Cleaning-Up-1"></a><a class="docs-heading-anchor-permalink" href="#Cleaning-Up" title="Permalink"></a></h2><pre><code class="language-julia hljs">import RxInferClientOpenAPI: delete_model_instance

response, _ = delete_model_instance(api, instance_id)
response</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">{
  &quot;message&quot;: &quot;Model instance deleted successfully&quot;
}
</code></pre><h2 id="Summary"><a class="docs-heading-anchor" href="#Summary">Summary</a><a id="Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Summary" title="Permalink"></a></h2><p>Understanding the difference between inference and learning is crucial for building effective continual learning systems. Inference provides immediate feedback using current parameters, while learning processes accumulated data and permanently updates the model. This separation allows for both real-time predictions and efficient batch learning, making it ideal for streaming data scenarios.</p><script type="module">import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
mermaid.initialize({
    startOnLoad: true,
    theme: "neutral"
});
</script></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../how-to-add-a-model/">« How to add a model</a><a class="docs-footer-nextpage" href="../continual-learning/">Continual learning »</a><div class="flexbox-break"></div><p class="footer-message">Created and sponsored by <a href="https://lazydynamics.com/">LazyDynamics</a>, powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>. Licensed under <a href="http://github.com/lazydynamics/RxInferServer?tab=readme-ov-file#license">AGPL-3.0</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Wednesday 1 October 2025 11:34">Wednesday 1 October 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
